import { Router, Request, Response, NextFunction } from 'express';
import express from 'express';
import { pool } from '../db/client.js';
import { z } from 'zod';
import { randomUUID } from 'crypto';
import { mkdir, writeFile, unlink } from 'fs/promises';
import { join, dirname } from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// Local uploads directory (for development)
const UPLOADS_DIR = join(__dirname, '../../uploads');

type RouterType = ReturnType<typeof Router>;
export const filesRouter: RouterType = Router();

// Auth middleware - check session cookie
async function requireAuth(req: Request, res: Response, next: NextFunction) {
  const sessionId = req.cookies?.session_id;
  if (!sessionId) {
    res.status(401).json({ error: 'Not authenticated' });
    return;
  }

  try {
    const result = await pool.query(
      `SELECT s.id, s.user_id, s.workspace_id, u.email, u.name
       FROM sessions s
       JOIN users u ON s.user_id = u.id
       WHERE s.id = $1 AND s.expires_at > now()`,
      [sessionId]
    );

    if (result.rows.length === 0) {
      res.status(401).json({ error: 'Session expired' });
      return;
    }

    // Extend session on activity
    await pool.query(
      `UPDATE sessions SET last_activity = now(), expires_at = now() + interval '15 minutes' WHERE id = $1`,
      [sessionId]
    );

    req.user = {
      id: result.rows[0].user_id,
      email: result.rows[0].email,
      name: result.rows[0].name,
      workspaceId: result.rows[0].workspace_id,
    };
    next();
  } catch (err) {
    console.error('Auth middleware error:', err);
    res.status(500).json({ error: 'Internal server error' });
  }
}

// Validation schemas
const uploadRequestSchema = z.object({
  filename: z.string().min(1).max(255),
  mimeType: z.string().min(1).max(100),
  sizeBytes: z.number().int().positive(),
});

// Allowed MIME types for security
const ALLOWED_MIME_TYPES = new Set([
  // Images
  'image/jpeg',
  'image/png',
  'image/gif',
  'image/webp',
  'image/svg+xml',
  // Documents
  'application/pdf',
  'application/msword',
  'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
  'application/vnd.ms-excel',
  'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
  'application/vnd.ms-powerpoint',
  'application/vnd.openxmlformats-officedocument.presentationml.presentation',
  // Text
  'text/plain',
  'text/csv',
  'text/markdown',
  // Archives
  'application/zip',
  'application/x-zip-compressed',
]);

// Blocked file extensions (security)
const BLOCKED_EXTENSIONS = new Set([
  '.exe', '.bat', '.cmd', '.sh', '.ps1', '.vbs', '.js', '.jar',
  '.msi', '.dll', '.com', '.scr', '.pif', '.application',
]);

function isAllowedFile(filename: string, mimeType: string): boolean {
  // Check extension
  const ext = filename.toLowerCase().slice(filename.lastIndexOf('.'));
  if (BLOCKED_EXTENSIONS.has(ext)) {
    return false;
  }

  // Check MIME type
  return ALLOWED_MIME_TYPES.has(mimeType);
}

// POST /api/files/upload - Get presigned URL for upload
// For local dev: returns a mock upload URL
// For production: would return S3 presigned URL
filesRouter.post('/upload', requireAuth, async (req: Request, res: Response) => {
  try {
    const validation = uploadRequestSchema.safeParse(req.body);
    if (!validation.success) {
      res.status(400).json({ error: 'Invalid request', details: validation.error.errors });
      return;
    }

    const { filename, mimeType, sizeBytes } = validation.data;
    const workspaceId = req.user!.workspaceId;
    const userId = req.user!.id;

    // Validate file type
    if (!isAllowedFile(filename, mimeType)) {
      res.status(400).json({ error: 'File type not allowed' });
      return;
    }

    // Generate unique S3 key / local path
    const fileId = randomUUID();
    const ext = filename.slice(filename.lastIndexOf('.'));
    const s3Key = `${workspaceId}/${fileId}${ext}`;

    // Create file record with 'pending' status
    const result = await pool.query(
      `INSERT INTO files (id, workspace_id, uploaded_by, filename, mime_type, size_bytes, s3_key, status)
       VALUES ($1, $2, $3, $4, $5, $6, $7, 'pending')
       RETURNING id`,
      [fileId, workspaceId, userId, filename, mimeType, sizeBytes, s3Key]
    );

    // For local development: use a local upload endpoint
    // For production: would generate S3 presigned URL
    const isProduction = process.env.NODE_ENV === 'production';
    const uploadUrl = isProduction
      ? await generateS3PresignedUrl(s3Key, mimeType)
      : `/api/files/${fileId}/local-upload`;

    res.json({
      fileId: result.rows[0].id,
      uploadUrl,
      s3Key,
    });
  } catch (error) {
    console.error('Error creating upload:', error);
    res.status(500).json({ error: 'Failed to create upload' });
  }
});

// Raw body parser for file uploads (100MB limit)
const rawBodyParser = express.raw({
  type: '*/*',
  limit: '100mb',
});

// POST /api/files/:id/local-upload - Local development upload endpoint
// In production, files upload directly to S3
filesRouter.post('/:id/local-upload', rawBodyParser, requireAuth, async (req: Request, res: Response) => {
  try {
    const fileId = req.params.id;
    const workspaceId = req.user!.workspaceId;

    // Verify file record exists and belongs to user's workspace
    const fileResult = await pool.query(
      `SELECT * FROM files WHERE id = $1 AND workspace_id = $2 AND status = 'pending'`,
      [fileId, workspaceId]
    );

    if (fileResult.rows.length === 0) {
      res.status(404).json({ error: 'File not found or already uploaded' });
      return;
    }

    const file = fileResult.rows[0];

    // Get raw body as buffer - handle various input types
    let buffer: Buffer;
    if (Buffer.isBuffer(req.body)) {
      buffer = req.body;
    } else if (req.body instanceof Uint8Array) {
      buffer = Buffer.from(req.body);
    } else if (typeof req.body === 'object' && req.body !== null) {
      // Handle ArrayBuffer or typed array wrapped in object
      const data = req.body.data || req.body;
      if (Array.isArray(data)) {
        buffer = Buffer.from(data);
      } else {
        buffer = Buffer.from(JSON.stringify(req.body));
      }
    } else if (typeof req.body === 'string') {
      buffer = Buffer.from(req.body, 'base64');
    } else {
      res.status(400).json({ error: 'Invalid file data format' });
      return;
    }

    if (buffer.length === 0) {
      res.status(400).json({ error: 'No file data received' });
      return;
    }

    // Ensure uploads directory exists
    const filePath = join(UPLOADS_DIR, file.s3_key);
    await mkdir(dirname(filePath), { recursive: true });

    // Write file
    await writeFile(filePath, buffer);

    // Update file status
    const cdnUrl = `/api/files/${fileId}/serve`;
    await pool.query(
      `UPDATE files SET status = 'uploaded', cdn_url = $1, updated_at = NOW() WHERE id = $2`,
      [cdnUrl, fileId]
    );

    res.json({ success: true });
  } catch (error) {
    console.error('Error uploading file locally:', error);
    res.status(500).json({ error: 'Failed to upload file' });
  }
});

// POST /api/files/:id/confirm - Confirm upload complete (for S3 direct uploads)
filesRouter.post('/:id/confirm', requireAuth, async (req: Request, res: Response) => {
  try {
    const fileId = req.params.id;
    const workspaceId = req.user!.workspaceId;

    // Verify file record exists and belongs to user's workspace
    const fileResult = await pool.query(
      `SELECT * FROM files WHERE id = $1 AND workspace_id = $2`,
      [fileId, workspaceId]
    );

    if (fileResult.rows.length === 0) {
      res.status(404).json({ error: 'File not found' });
      return;
    }

    const file = fileResult.rows[0];

    // For production: verify file exists in S3
    // For local dev: file was already saved in local-upload

    // Generate CDN URL
    const isProduction = process.env.NODE_ENV === 'production';
    const cdnDomain = process.env.CDN_DOMAIN || 'localhost:3000';
    const cdnUrl = isProduction
      ? `https://${cdnDomain}/${file.s3_key}`
      : `/api/files/${fileId}/serve`;

    // Update file status
    await pool.query(
      `UPDATE files SET status = 'uploaded', cdn_url = $1, updated_at = NOW() WHERE id = $2`,
      [cdnUrl, fileId]
    );

    res.json({
      fileId,
      cdnUrl,
      status: 'uploaded',
    });
  } catch (error) {
    console.error('Error confirming upload:', error);
    res.status(500).json({ error: 'Failed to confirm upload' });
  }
});

// GET /api/files/:id/serve - Serve file (local development only)
filesRouter.get('/:id/serve', async (req: Request, res: Response) => {
  try {
    const fileId = req.params.id;

    // Get file record
    const fileResult = await pool.query(
      `SELECT * FROM files WHERE id = $1 AND status = 'uploaded'`,
      [fileId]
    );

    if (fileResult.rows.length === 0) {
      res.status(404).json({ error: 'File not found' });
      return;
    }

    const file = fileResult.rows[0];
    const filePath = join(UPLOADS_DIR, file.s3_key);

    // Set content type and serve file
    res.setHeader('Content-Type', file.mime_type);
    res.setHeader('Content-Disposition', `inline; filename="${file.filename}"`);
    res.sendFile(filePath);
  } catch (error) {
    console.error('Error serving file:', error);
    res.status(500).json({ error: 'Failed to serve file' });
  }
});

// GET /api/files/:id - Get file metadata
filesRouter.get('/:id', requireAuth, async (req: Request, res: Response) => {
  try {
    const fileId = req.params.id;
    const workspaceId = req.user!.workspaceId;

    const result = await pool.query(
      `SELECT id, filename, mime_type, size_bytes, cdn_url, status, created_at
       FROM files WHERE id = $1 AND workspace_id = $2`,
      [fileId, workspaceId]
    );

    if (result.rows.length === 0) {
      res.status(404).json({ error: 'File not found' });
      return;
    }

    res.json(result.rows[0]);
  } catch (error) {
    console.error('Error getting file:', error);
    res.status(500).json({ error: 'Failed to get file' });
  }
});

// DELETE /api/files/:id - Delete a file
filesRouter.delete('/:id', requireAuth, async (req: Request, res: Response) => {
  try {
    const fileId = req.params.id;
    const workspaceId = req.user!.workspaceId;

    // Get file record
    const fileResult = await pool.query(
      `SELECT * FROM files WHERE id = $1 AND workspace_id = $2`,
      [fileId, workspaceId]
    );

    if (fileResult.rows.length === 0) {
      res.status(404).json({ error: 'File not found' });
      return;
    }

    const file = fileResult.rows[0];

    // Delete from storage (local or S3)
    const isProduction = process.env.NODE_ENV === 'production';
    if (isProduction) {
      // TODO: Delete from S3
    } else {
      try {
        const filePath = join(UPLOADS_DIR, file.s3_key);
        await unlink(filePath);
      } catch {
        // File might not exist, ignore error
      }
    }

    // Delete database record
    await pool.query('DELETE FROM files WHERE id = $1', [fileId]);

    res.json({ success: true });
  } catch (error) {
    console.error('Error deleting file:', error);
    res.status(500).json({ error: 'Failed to delete file' });
  }
});

// Placeholder for S3 presigned URL generation (production)
async function generateS3PresignedUrl(s3Key: string, contentType: string): Promise<string> {
  // In production, this would use AWS SDK to generate presigned URL
  // For now, return a placeholder
  const bucketName = process.env.S3_BUCKET_NAME || 'ship-uploads';
  const region = process.env.AWS_REGION || 'us-east-1';

  // This is a placeholder - real implementation would use @aws-sdk/s3-request-presigner
  return `https://${bucketName}.s3.${region}.amazonaws.com/${s3Key}?presigned=true`;
}
